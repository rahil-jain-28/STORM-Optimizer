{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet32.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEbxDH3CY0jk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87be44f7-d3e2-4f16-d29c-459024ec1cf7"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Check if CUDA is available\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
        "\n",
        "if device==\"cuda\":\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0rISRXbtYLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    #Basic Block with indentity downsampling \n",
        "    def __init__(self,in_channels,out_channels,identity_downsample=None,stride=1):\n",
        "      super(BasicBlock,self).__init__()\n",
        "      self.conv1= nn.Conv2d(in_channels,out_channels,kernel_size=3,stride=stride,padding=1)\n",
        "      self.bn1= nn.BatchNorm2d(out_channels)\n",
        "      self.conv2= nn.Conv2d(out_channels,out_channels,kernel_size=3,stride=1,padding=1)\n",
        "      self.bn2= nn.BatchNorm2d(out_channels)\n",
        "      self.relu= nn.ReLU()\n",
        "      self.identity_downsample= identity_downsample\n",
        "    \n",
        "    def forward(self,x):\n",
        "      identity=x\n",
        "      x = self.conv1(x)\n",
        "      x = self.bn1(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.conv2(x)\n",
        "      x = self.bn2(x)\n",
        "      x = self.relu(x)\n",
        "      if self.identity_downsample is not None:\n",
        "        identity = self.identity_downsample(identity)\n",
        "      \n",
        "      # Shortcut connection\n",
        "      x += identity\n",
        "      x = self.relu(x)\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3e7i4SOtfVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet32(nn.Module):\n",
        "    def __init__(self,block,layers,image_channels,num_classes):\n",
        "      super(ResNet32,self).__init__()\n",
        "      self.in_channels = 16\n",
        "      self.conv1 = nn.Conv2d(image_channels,16,kernel_size= 3,stride=1,padding=1)\n",
        "      self.bn1 = nn.BatchNorm2d(16)\n",
        "      self.relu = nn.ReLU()\n",
        "      self.layer1 = self._make_layer(block,5,out_channels=16,stride=1)\n",
        "      self.layer2 = self._make_layer(block,5,out_channels=32,stride=2)\n",
        "      self.layer3 = self._make_layer(block,5,out_channels=64,stride=2)\n",
        "      self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "      self.fc = nn.Linear(64,num_classes)\n",
        "      self.softmax = nn.Softmax(dim=1)\n",
        "  \n",
        "    def forward(self,x): \n",
        "      # First Convolutional layer\n",
        "      x = self.conv1(x)\n",
        "      x = self.bn1(x)\n",
        "      x = self.relu(x)\n",
        "      # Layers with Feature map size = 32\n",
        "      x = self.layer1(x)\n",
        "      # Layers with Feature map size = 16\n",
        "      x = self.layer2(x)\n",
        "      # Layers wiht Feature map size = 8\n",
        "      x = self.layer3(x)\n",
        "      #Average pooling and Output layer\n",
        "      x = self.avgpool(x)\n",
        "      x = x.reshape(x.shape[0],-1)\n",
        "      x = self.fc(x)\n",
        "      x = self.softmax(x)\n",
        "      return x\n",
        "\n",
        "    def _make_layer(self,block,num_residual_blocks,out_channels,stride):\n",
        "      identity_downsample= None\n",
        "      layers = []\n",
        "\n",
        "      #Identity Downsampling\n",
        "      if stride!=1 or self.in_channels!= out_channels:\n",
        "        identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels,out_channels,kernel_size=1,stride=stride),\n",
        "                                            nn.BatchNorm2d(out_channels))\n",
        "      layers.append(block(self.in_channels,out_channels,identity_downsample,stride))\n",
        "      \n",
        "      self.in_channels = out_channels\n",
        "      for i in range(num_residual_blocks - 1):\n",
        "          layers.append(block(self.in_channels,out_channels))\n",
        "\n",
        "      #Stacking all layers\n",
        "      return nn.Sequential(*layers)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANG2XoZ2a632",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ResNet_32(img_channels=3,num_classes = 10):\n",
        "    return ResNet32(BasicBlock,[5,5,5,5], img_channels,num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMPzVezlt5mc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "964916fc-7159-4992-fcfd-91b52e3961aa"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "#Moving model to gpu if available and Printing model summary\n",
        "model = ResNet_32(3, 10).to(device)\n",
        "summary(model, (3, 32, 32))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             448\n",
            "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
            "              ReLU-3           [-1, 16, 32, 32]               0\n",
            "            Conv2d-4           [-1, 16, 32, 32]           2,320\n",
            "       BatchNorm2d-5           [-1, 16, 32, 32]              32\n",
            "              ReLU-6           [-1, 16, 32, 32]               0\n",
            "            Conv2d-7           [-1, 16, 32, 32]           2,320\n",
            "       BatchNorm2d-8           [-1, 16, 32, 32]              32\n",
            "              ReLU-9           [-1, 16, 32, 32]               0\n",
            "             ReLU-10           [-1, 16, 32, 32]               0\n",
            "       BasicBlock-11           [-1, 16, 32, 32]               0\n",
            "           Conv2d-12           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-13           [-1, 16, 32, 32]              32\n",
            "             ReLU-14           [-1, 16, 32, 32]               0\n",
            "           Conv2d-15           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-16           [-1, 16, 32, 32]              32\n",
            "             ReLU-17           [-1, 16, 32, 32]               0\n",
            "             ReLU-18           [-1, 16, 32, 32]               0\n",
            "       BasicBlock-19           [-1, 16, 32, 32]               0\n",
            "           Conv2d-20           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-21           [-1, 16, 32, 32]              32\n",
            "             ReLU-22           [-1, 16, 32, 32]               0\n",
            "           Conv2d-23           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-24           [-1, 16, 32, 32]              32\n",
            "             ReLU-25           [-1, 16, 32, 32]               0\n",
            "             ReLU-26           [-1, 16, 32, 32]               0\n",
            "       BasicBlock-27           [-1, 16, 32, 32]               0\n",
            "           Conv2d-28           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-29           [-1, 16, 32, 32]              32\n",
            "             ReLU-30           [-1, 16, 32, 32]               0\n",
            "           Conv2d-31           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-32           [-1, 16, 32, 32]              32\n",
            "             ReLU-33           [-1, 16, 32, 32]               0\n",
            "             ReLU-34           [-1, 16, 32, 32]               0\n",
            "       BasicBlock-35           [-1, 16, 32, 32]               0\n",
            "           Conv2d-36           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-37           [-1, 16, 32, 32]              32\n",
            "             ReLU-38           [-1, 16, 32, 32]               0\n",
            "           Conv2d-39           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-40           [-1, 16, 32, 32]              32\n",
            "             ReLU-41           [-1, 16, 32, 32]               0\n",
            "             ReLU-42           [-1, 16, 32, 32]               0\n",
            "       BasicBlock-43           [-1, 16, 32, 32]               0\n",
            "           Conv2d-44           [-1, 32, 16, 16]           4,640\n",
            "      BatchNorm2d-45           [-1, 32, 16, 16]              64\n",
            "             ReLU-46           [-1, 32, 16, 16]               0\n",
            "           Conv2d-47           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-48           [-1, 32, 16, 16]              64\n",
            "             ReLU-49           [-1, 32, 16, 16]               0\n",
            "           Conv2d-50           [-1, 32, 16, 16]             544\n",
            "      BatchNorm2d-51           [-1, 32, 16, 16]              64\n",
            "             ReLU-52           [-1, 32, 16, 16]               0\n",
            "       BasicBlock-53           [-1, 32, 16, 16]               0\n",
            "           Conv2d-54           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-55           [-1, 32, 16, 16]              64\n",
            "             ReLU-56           [-1, 32, 16, 16]               0\n",
            "           Conv2d-57           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-58           [-1, 32, 16, 16]              64\n",
            "             ReLU-59           [-1, 32, 16, 16]               0\n",
            "             ReLU-60           [-1, 32, 16, 16]               0\n",
            "       BasicBlock-61           [-1, 32, 16, 16]               0\n",
            "           Conv2d-62           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-63           [-1, 32, 16, 16]              64\n",
            "             ReLU-64           [-1, 32, 16, 16]               0\n",
            "           Conv2d-65           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-66           [-1, 32, 16, 16]              64\n",
            "             ReLU-67           [-1, 32, 16, 16]               0\n",
            "             ReLU-68           [-1, 32, 16, 16]               0\n",
            "       BasicBlock-69           [-1, 32, 16, 16]               0\n",
            "           Conv2d-70           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-71           [-1, 32, 16, 16]              64\n",
            "             ReLU-72           [-1, 32, 16, 16]               0\n",
            "           Conv2d-73           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-74           [-1, 32, 16, 16]              64\n",
            "             ReLU-75           [-1, 32, 16, 16]               0\n",
            "             ReLU-76           [-1, 32, 16, 16]               0\n",
            "       BasicBlock-77           [-1, 32, 16, 16]               0\n",
            "           Conv2d-78           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-79           [-1, 32, 16, 16]              64\n",
            "             ReLU-80           [-1, 32, 16, 16]               0\n",
            "           Conv2d-81           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-82           [-1, 32, 16, 16]              64\n",
            "             ReLU-83           [-1, 32, 16, 16]               0\n",
            "             ReLU-84           [-1, 32, 16, 16]               0\n",
            "       BasicBlock-85           [-1, 32, 16, 16]               0\n",
            "           Conv2d-86             [-1, 64, 8, 8]          18,496\n",
            "      BatchNorm2d-87             [-1, 64, 8, 8]             128\n",
            "             ReLU-88             [-1, 64, 8, 8]               0\n",
            "           Conv2d-89             [-1, 64, 8, 8]          36,928\n",
            "      BatchNorm2d-90             [-1, 64, 8, 8]             128\n",
            "             ReLU-91             [-1, 64, 8, 8]               0\n",
            "           Conv2d-92             [-1, 64, 8, 8]           2,112\n",
            "      BatchNorm2d-93             [-1, 64, 8, 8]             128\n",
            "             ReLU-94             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-95             [-1, 64, 8, 8]               0\n",
            "           Conv2d-96             [-1, 64, 8, 8]          36,928\n",
            "      BatchNorm2d-97             [-1, 64, 8, 8]             128\n",
            "             ReLU-98             [-1, 64, 8, 8]               0\n",
            "           Conv2d-99             [-1, 64, 8, 8]          36,928\n",
            "     BatchNorm2d-100             [-1, 64, 8, 8]             128\n",
            "            ReLU-101             [-1, 64, 8, 8]               0\n",
            "            ReLU-102             [-1, 64, 8, 8]               0\n",
            "      BasicBlock-103             [-1, 64, 8, 8]               0\n",
            "          Conv2d-104             [-1, 64, 8, 8]          36,928\n",
            "     BatchNorm2d-105             [-1, 64, 8, 8]             128\n",
            "            ReLU-106             [-1, 64, 8, 8]               0\n",
            "          Conv2d-107             [-1, 64, 8, 8]          36,928\n",
            "     BatchNorm2d-108             [-1, 64, 8, 8]             128\n",
            "            ReLU-109             [-1, 64, 8, 8]               0\n",
            "            ReLU-110             [-1, 64, 8, 8]               0\n",
            "      BasicBlock-111             [-1, 64, 8, 8]               0\n",
            "          Conv2d-112             [-1, 64, 8, 8]          36,928\n",
            "     BatchNorm2d-113             [-1, 64, 8, 8]             128\n",
            "            ReLU-114             [-1, 64, 8, 8]               0\n",
            "          Conv2d-115             [-1, 64, 8, 8]          36,928\n",
            "     BatchNorm2d-116             [-1, 64, 8, 8]             128\n",
            "            ReLU-117             [-1, 64, 8, 8]               0\n",
            "            ReLU-118             [-1, 64, 8, 8]               0\n",
            "      BasicBlock-119             [-1, 64, 8, 8]               0\n",
            "          Conv2d-120             [-1, 64, 8, 8]          36,928\n",
            "     BatchNorm2d-121             [-1, 64, 8, 8]             128\n",
            "            ReLU-122             [-1, 64, 8, 8]               0\n",
            "          Conv2d-123             [-1, 64, 8, 8]          36,928\n",
            "     BatchNorm2d-124             [-1, 64, 8, 8]             128\n",
            "            ReLU-125             [-1, 64, 8, 8]               0\n",
            "            ReLU-126             [-1, 64, 8, 8]               0\n",
            "      BasicBlock-127             [-1, 64, 8, 8]               0\n",
            "AdaptiveAvgPool2d-128             [-1, 64, 1, 1]               0\n",
            "          Linear-129                   [-1, 10]             650\n",
            "         Softmax-130                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 468,138\n",
            "Trainable params: 468,138\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 9.31\n",
            "Params size (MB): 1.79\n",
            "Estimated Total Size (MB): 11.11\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnDMTfJfvYfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}